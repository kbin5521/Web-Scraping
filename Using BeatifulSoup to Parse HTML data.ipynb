{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's do some simple examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1\n",
    "# we have a simple html text\n",
    "htmltxt = '<p>Hello World<p>'\n",
    "parsed_txt = BeautifulSoup(htmltxt, 'lxml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### There are 3 ways of parser, let's see the advantages and disadvantages of each parser method.\n",
    "1. html.parser - BeautifulSoup(markup, \"html.parser\")\n",
    "-Advantages: Batteries included, Decent Speed, Lenient\n",
    "-Disadvantages: Not very lenient (before Python 2.7.3 or 3.2.2)\n",
    "2. lxml - BeautifulSoup(markup, \"lxml\")\n",
    "-Advantages: Very fast, lenient\n",
    "-Disadvantages: External C dependency\n",
    "3. html5lib - BeautifulSoup(markup, \"html5lib\")\n",
    "-Advantages: Extremely lenient, Parses pages the same way a web browser does, Creates valid HTML5\n",
    "-Disadvantages: Very slow, External Python dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The type of parsed_txt is:  <class 'bs4.BeautifulSoup'>\n"
     ]
    }
   ],
   "source": [
    "# check type\n",
    "print('The type of parsed_txt is: ', type(parsed_txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html><body><p>Hello World</p><p></p></body></html>\n",
      "Hello World\n"
     ]
    }
   ],
   "source": [
    "# Extract text\n",
    "print(parsed_txt)\n",
    "print(parsed_txt.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World\n",
      "This is a link\n"
     ]
    }
   ],
   "source": [
    "# Example 2\n",
    "mytxt = \"\"\"\n",
    "<h1>Hello World</h1>\n",
    "<p>This is a <a href=\"http://example.com\">link</a></p>\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(mytxt, 'lxml')\n",
    "print(soup.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding a tage with find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generally, we don't want to just spit all of the tag-stripped text of an HTML document. \n",
    "# Usually, we want to extract text from just a few specific elements.\n",
    "# Example 3\n",
    "mytxt = \"\"\"\n",
    "<h1>Hello World</h1>\n",
    "<p>This is a <a href=\"http://example.com\">link</a></p>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mytxt contains 3 tags: \n",
    "# 1. A headline, <h1>\n",
    "# 2. A paragragh, <p>\n",
    "# 3. Within the paragragh, a hyperlink, ,<a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(mytxt, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>Hello World</h1>\n",
      "<p>This is a <a href=\"http://example.com\">link</a></p>\n",
      "<a href=\"http://example.com\">link</a>\n",
      "Hello World\n",
      "This is a link\n",
      "link\n",
      "<class 'bs4.element.Tag'>\n"
     ]
    }
   ],
   "source": [
    "print(soup.find('h1'))\n",
    "print(soup.find('p'))\n",
    "print(soup.find('a'))\n",
    "print(soup.find('h1').text)\n",
    "print(soup.find('p').text)\n",
    "print(soup.find('a').text)\n",
    "print(type(soup.find('h1')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting attributes from a tag with attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.element.Tag'>\n",
      "<class 'dict'>\n",
      "{'href': 'http://example.com'}\n",
      "http://example.com\n"
     ]
    }
   ],
   "source": [
    "# In the previous example, how can we extract the link?\n",
    "# use attrs function to extract the link\n",
    "link = soup.find('a')\n",
    "print(type(link))\n",
    "# Take a look at the type of the link attributes\n",
    "print(type(link.attrs))\n",
    "print(link.attrs)\n",
    "# stripe out the link\n",
    "print(link.attrs['href'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding multiple elements with find_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html><body><p>Visit the <a href=\"http://www.nytimes.com\">New York Times</a></p>\n",
       "<p>Visit the <a href=\"http://www.wsj.com\">Wall Street Journal</a></p>\n",
       "</body></html>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example 4\n",
    "moretxt = \"\"\"\n",
    "<p>Visit the <a href='http://www.nytimes.com'>New York Times</a></p>\n",
    "<p>Visit the <a href='http://www.wsj.com'>Wall Street Journal</a></p>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(moretxt, 'lxml')\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.element.ResultSet'>\n",
      "[<p>Visit the <a href=\"http://www.nytimes.com\">New York Times</a></p>, <p>Visit the <a href=\"http://www.wsj.com\">Wall Street Journal</a></p>]\n",
      "2\n",
      "Visit the New York Times\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "tags = soup.find_all('p')\n",
    "print(type(tags))\n",
    "# a ResultSet acts very much like list3\n",
    "print(tags)\n",
    "print(len(tags))\n",
    "print(tags[0].text)\n",
    "print(tags[0].attrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding nested elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example 5\n",
    "evenmoretxt = \"\"\"\n",
    "<h1><a href=\"http://www.a.com\">Awesome</a></h1>\n",
    "<h1><a href=\"http://www.b.com\">Really Awesome</a></h1>\n",
    "\n",
    "<div><a href=\"http://na.com\">Ignore me</a></div>\n",
    "<div><a href=\"http://127.0.0.1\">Ignore me again</a></div>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(evenmoretxt, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<h1><a href=\"http://www.a.com\">Awesome</a></h1>,\n",
       " <h1><a href=\"http://www.b.com\">Really Awesome</a></h1>]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heads = soup.find_all('h1')\n",
    "heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"http://www.a.com\">Awesome</a>,\n",
       " <a href=\"http://www.b.com\">Really Awesome</a>]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links = []\n",
    "for h in heads:\n",
    "    a = h.find('a')\n",
    "    links.append(a)\n",
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
